{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will run the Fortran model with a bias corrector scheme implemented as a random forest which is called at the end of each timestep. We'll interactively look at the model state in the middle of execution, to try to understand a bit about the behavior of the bias corrector. This is a proof-of-concept example - the random forest scheme is not necessarily performant or even stable over many time steps. The purpose is to demonstrate the interactive execution of the Fortran model in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example requires ipyparallel configured with MPI in order to run. We have given an example which provides this environment using Docker in examples/jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the Fortran model, we need to be working in a run directory. Let's download one we've prepared for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://storage.googleapis.com/vcm-ml-public/agu/c48_1_day.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -zxvf c48_1_day.tar.gz\n",
    "mv rundir rundir_c48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will start the MPI cluster used after we run %autopx. Do not be alarmed by the red text output, this is triggered by the --debug flag. Using this flag will provide us with extra logging information in the case of a crash. If you do get a crash or hang, refer to the last section of this notebook which provides some tools for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if you get a crash, add --debug to this command to put more info in logs\n",
    "# logs are in /root/.ipython/profile_mpi/log\n",
    "ipcluster start --profile=mpi -n 6 --daemonize --debug\n",
    "sleep 10  # command is asynchronous, so let's wait to avoid an error in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we configure the notebook to use this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi', targets='all', block=True)\n",
    "dv = rc[:]\n",
    "dv.activate()\n",
    "dv.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running IPython Parallel on {0} MPI engines\".format(len(rc.ids)))\n",
    "print(\"Commands in the following cells will be executed in parallel (disable with %autopx)\")\n",
    "%autopx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that we're running in parallel using mpi4py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "mpi_size = comm.Get_size()\n",
    "mpi_rank = comm.Get_rank()\n",
    "\n",
    "print(f\"Number of ranks is {mpi_size}.\")\n",
    "print(f\"I am rank {mpi_rank}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we move into the run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"rundir_c48\")\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stage is set. We're running in parallel using MPI, and we're in a run directory. Now we can start running the model! First we will import the packages used in the rest of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fv3gfs.wrapper\n",
    "from fv3gfs.util import (\n",
    "    TilePartitioner, CubedSpherePartitioner, CubedSphereCommunicator, Quantity,\n",
    "    X_DIM, Y_DIM, Z_DIM, X_INTERFACE_DIM, Y_INTERFACE_DIM\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import f90nml\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = f90nml.read(\"input.nml\")\n",
    "layout = namelist[\"fv_core_nml\"][\"layout\"]\n",
    "timestep = timedelta(seconds=namelist[\"coupler_nml\"][\"dt_atmos\"])\n",
    "cube = CubedSphereCommunicator(\n",
    "    MPI.COMM_WORLD,\n",
    "    CubedSpherePartitioner(\n",
    "        TilePartitioner(layout)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y(shape):\n",
    "    \"\"\"Get coordinate locations for plotting a global field as a flattened cube.\"\"\"\n",
    "    X = np.zeros([shape[0], shape[1] + 1, shape[2] + 1]) + np.arange(0, shape[1] + 1)[None, :, None]\n",
    "    Y = np.zeros([shape[0], shape[1] + 1, shape[2] + 1]) + np.arange(0, shape[2] + 1)[None, None, :]\n",
    "    # offset and rotate the data for each rank, with zero at the \"center\"\n",
    "    for tile, shift_x, shift_y, n_rotations in [\n",
    "        (1, 1, 0, 0), (2, 0, 1, -1), (3, 2, 0, 1), (4, -1, 0, 1), (5, 0, -1, 0)\n",
    "    ]:\n",
    "        X[tile, :, :] += shift_x * shape[1]\n",
    "        Y[tile, :, :] += shift_y * shape[2]\n",
    "        X[tile, :, :] = np.rot90(X[tile, :, :], n_rotations)\n",
    "        Y[tile, :, :] = np.rot90(Y[tile, :, :], n_rotations)\n",
    "    return X, Y\n",
    "\n",
    "def plot_global(quantity, cube, vmin, vmax):\n",
    "    \"\"\"Plot a quantity globally on the root rank as a flattened cube.\"\"\"\n",
    "    assert quantity.dims == (Y_DIM, X_DIM), \"example written to plot 2D fields\"\n",
    "    global_quantity = cube.gather(quantity)\n",
    "    if global_quantity is not None:  # only on first rank\n",
    "        X, Y = get_X_Y(global_quantity.extent)\n",
    "        plt.figure(figsize=(9, 5.5))\n",
    "        for tile in range(global_quantity.extent[0]):\n",
    "            im = plt.pcolormesh(\n",
    "                X[tile, :, :],\n",
    "                Y[tile, :, :],\n",
    "                global_quantity.view[tile, :, :].T,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "        )\n",
    "        plt.colorbar(im)\n",
    "        # we don't plt.show() here in case you want to run more commands after plot_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fv3gfs.wrapper.initialize()\n",
    "# for i in range(fv3gfs.wrapper.get_step_count()):\n",
    "#     fv3gfs.wrapper.step_dynamics()\n",
    "#     fv3gfs.wrapper.step_physics()\n",
    "#     fv3gfs.wrapper.save_intermediate_restart_if_enabled()\n",
    "# fv3gfs.wrapper.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = fv3gfs.wrapper.examples.get_random_forest()\n",
    "fv3gfs.wrapper.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our MPI communication and plotting code is working correctly by plotting surface pressure, which is a reasonable proxy for surface height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global(\n",
    "    fv3gfs.wrapper.get_state([\"surface_pressure\"])[\"surface_pressure\"],\n",
    "    cube,\n",
    "    vmin=95e3,\n",
    "    vmax=103e3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this model with our machine learning augmentation, we get significant drying of the atmosphere. We want to diagnose why, and better understand the issue. To quickly look at global structure of mosture, let's define column total water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_total_water(specific_humidity, pressure_thickness):\n",
    "    assert specific_humidity.dims == (Z_DIM, Y_DIM, X_DIM)\n",
    "    assert specific_humidity.units == \"kg/kg\", specific_humidity.units\n",
    "    assert pressure_thickness.dims == (Z_DIM, Y_DIM, X_DIM)\n",
    "    assert pressure_thickness.units == \"Pa\", pressure_thickness.units\n",
    "    mass = pressure_thickness.view[:] * 9.81\n",
    "    total_water = np.sum(mass * specific_humidity.view[:], axis=0)\n",
    "    return Quantity(\n",
    "        total_water,\n",
    "        dims=(Y_DIM, X_DIM),\n",
    "        units=\"kg\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look in detail at the first time step. Let's see how much of the first step moisture tendency is due to dynamics, physics, and our machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\"specific_humidity\", \"pressure_thickness_of_atmospheric_layer\")\n",
    "state_initial = fv3gfs.wrapper.get_state(names)\n",
    "total_water_initial = column_total_water(\n",
    "    state_initial[\"specific_humidity\"],\n",
    "    state_initial[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_water_initial.view[:].min(), total_water_initial.view[:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global(total_water_initial, cube, vmin=0, vmax=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv3gfs.wrapper.step_dynamics()\n",
    "state_after_dynamics = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_dynamics = column_total_water(\n",
    "    state_after_dynamics[\"specific_humidity\"],\n",
    "    state_after_dynamics[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv3gfs.wrapper.step_physics()\n",
    "fv3gfs.wrapper.save_intermediate_restart_if_enabled()\n",
    "state_after_physics = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_physics = column_total_water(\n",
    "    state_after_physics[\"specific_humidity\"],\n",
    "    state_after_physics[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fv3gfs.wrapper.get_state(rf_model.inputs)\n",
    "rf_model.update(state, timestep=timestep)\n",
    "fv3gfs.wrapper.set_state_mass_conserving(state)\n",
    "state_after_rf = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_rf = column_total_water(\n",
    "    state_after_rf[\"specific_humidity\"],\n",
    "    state_after_rf[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Quantity hopes to make your life easier in the long term by being strict about units, it doesn't currently have arithmetic routines implemented. Let's make some simple ones which are good enough for our purposes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract(q1, q2):\n",
    "    assert q1.units == q2.units\n",
    "    data_array = q1.data_array - q2.data_array\n",
    "    data_array.attrs[\"units\"] = q1.units\n",
    "    return Quantity.from_data_array(data_array)\n",
    "\n",
    "def multiply(q1, q2):\n",
    "    # this will eventually be implemented for Quantity as a units-aware calculation\n",
    "    data_array = q1.data_array * q2.data_array\n",
    "    data_array.attrs[\"units\"] = \"unknown\"\n",
    "    return Quantity.from_data_array(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global(\n",
    "    subtract(total_water_after_dynamics, total_water_initial),\n",
    "    cube,\n",
    "    vmin=-50,\n",
    "    vmax=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_global(\n",
    "    subtract(total_water_after_physics, total_water_after_dynamics),\n",
    "    cube,\n",
    "    vmin=-50,\n",
    "    vmax=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global(\n",
    "    subtract(total_water_after_rf, total_water_after_physics),\n",
    "    cube,\n",
    "    vmin=-50,\n",
    "    vmax=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correction from the random forest doesn't even appear at the same scale as we used for the dynamics and physics. Because we're running interactively, we can inspect its values to determine an appropriate plotting range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the random forest corrector is mainly drying out the atmosphere. It isn't immediately obvious why it's choosing to dry out certain areas. Personally, I'm curious about whether the drying is happening mostly in regions where the physics is drying or moistening the atmosphere. For areas where the random forest is doing anything, let's plot whether the signs agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_update = subtract(total_water_after_rf, total_water_after_physics)\n",
    "result = multiply(\n",
    "    rf_update,\n",
    "    subtract(total_water_after_physics, total_water_after_dynamics)\n",
    ")\n",
    "result.view[:] = np.sign(result.view[:])\n",
    "result.view[:][np.abs(rf_update.view[:]) < 5] = 0.  # 5 chosen by testing different numbers\n",
    "print(result.view[:].min(), result.view[:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global(result, cube, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing this tells us the random forest is mostly precipitating in regions where the physics is moistening the column. Look more closely at the blob in region x: (75, 100) and y: (20:40). If we look back at the plot of the physics update, we can see the sharp yellow areas where the physics and random forest agree on sign are grid-scale precipitation. In this region, the random forest appears to indicate the physics parameterization is under-precipitating. We can confirm this by looking at a vertical column from this region, and seeing if the drying tendency from the random forest looks like precipitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't remember the orientation and placement of the ranks, so let's plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "quantity = copy.deepcopy(result)\n",
    "quantity.view[:] = cube.rank\n",
    "plot_global(quantity, cube, vmin=0, vmax=5)\n",
    "quantity.view[:, :] = np.arange(quantity.extent[0])[:, None]\n",
    "plot_global(quantity, cube, vmin=0, vmax=quantity.extent[0])\n",
    "quantity.view[:, :] = np.arange(quantity.extent[1])[None, :]\n",
    "plot_global(quantity, cube, vmin=0, vmax=quantity.extent[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we want to inspect rank 1, whose first axis increases along x and second axis increases along y in the plot. We can use this information to ballpark the region we want to be looking at, and make a new plot to confirm we've selected the right index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 85 - 48  # rank 1's area starts at x=48\n",
    "iy = 25\n",
    "\n",
    "# result is the -1/0/1 plot from earlier for sign agreement\n",
    "quantity = copy.deepcopy(result)\n",
    "if cube.rank == 1:\n",
    "    quantity.view[iy, ix] = 2\n",
    "plot_global(quantity, cube, vmin=-1, vmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our index is well within the region where the random forest is lightly precipitating and the physics is not. Let's take a look at the vertical profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cube.rank == 1:\n",
    "    p = np.cumsum(state[\"pressure_thickness_of_atmospheric_layer\"].view[:, iy, ix], axis=0)\n",
    "    physics_update = subtract(\n",
    "        state_after_physics[\"specific_humidity\"],\n",
    "        state_after_dynamics[\"specific_humidity\"]\n",
    "    )\n",
    "    rf_update = subtract(\n",
    "        state_after_rf[\"specific_humidity\"],\n",
    "        state_after_physics[\"specific_humidity\"]\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.plot(state_after_dynamics[\"specific_humidity\"].view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"specific_humidity\")\n",
    "    plt.figure()\n",
    "    plt.plot(physics_update.view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"physics update\")\n",
    "    plt.figure()\n",
    "    plt.plot(rf_update.view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"random forest update\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots tell us that we cannot reasonably call what the random forest is doing in this case \"precipitation\". The drying is happening broadly throughout the troposphere, and is not particularly concentrated where there is humidity or where the physics routines are precipitating (at and below 800 hPa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strong negative humidity tendencies in the uppper troposphere are concerning, given the model does not have very much moisture at these levels. It's likely to cause negative humidity. Let's evolve the model a few hours, and see if the drying lessens or stops. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_in_hour = 60*60\n",
    "timesteps_in_hour = seconds_in_hour / timestep.total_seconds()\n",
    "total_timesteps = int(3 * timesteps_in_hour)\n",
    "print(total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_timesteps):\n",
    "    fv3gfs.wrapper.step()\n",
    "    state = fv3gfs.wrapper.get_state(rf_model.inputs)\n",
    "    rf_model.update(state, timestep=timestep)\n",
    "    fv3gfs.wrapper.set_state_mass_conserving(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv3gfs.wrapper.step_dynamics()\n",
    "state_after_dynamics = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_dynamics = column_total_water(\n",
    "    state_after_dynamics[\"specific_humidity\"],\n",
    "    state_after_dynamics[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv3gfs.wrapper.step_physics()\n",
    "fv3gfs.wrapper.save_intermediate_restart_if_enabled()\n",
    "state_after_physics = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_physics = column_total_water(\n",
    "    state_after_physics[\"specific_humidity\"],\n",
    "    state_after_physics[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fv3gfs.wrapper.get_state(rf_model.inputs)\n",
    "rf_model.update(state, timestep=timestep)\n",
    "fv3gfs.wrapper.set_state_mass_conserving(state)\n",
    "state_after_rf = fv3gfs.wrapper.get_state(names)\n",
    "total_water_after_rf = column_total_water(\n",
    "    state_after_rf[\"specific_humidity\"],\n",
    "    state_after_rf[\"pressure_thickness_of_atmospheric_layer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cube.rank == 1:\n",
    "    p = np.cumsum(state[\"pressure_thickness_of_atmospheric_layer\"].view[:, iy, ix], axis=0)\n",
    "    physics_update = subtract(\n",
    "        state_after_physics[\"specific_humidity\"],\n",
    "        state_after_dynamics[\"specific_humidity\"]\n",
    "    )\n",
    "    rf_update = subtract(\n",
    "        state_after_rf[\"specific_humidity\"],\n",
    "        state_after_physics[\"specific_humidity\"]\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.plot(state_after_dynamics[\"specific_humidity\"].view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"specific_humidity\")\n",
    "    plt.figure()\n",
    "    plt.plot(physics_update.view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"physics update\")\n",
    "    plt.figure()\n",
    "    plt.plot(rf_update.view[:, iy, ix], p)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"random forest update\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's encouraging that we see the negative tendencies in the upper troposphere lessen. There's an interesting peak around 700 hPa which seems to be getting strengthened by the random forest. In an interactive notebook, we could continue our analysis by saving fields over the next few hours and producing an animation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook could go on forever, but we'll stop here. Hopefully this has shown the strength of being able to use interactive execution of a Fortran model to diagnose model behavior. This is not limited to investigating machine learning parameterizations, or even Python parameterizations. A researcher could augment an existing Fortran model with new Fortran code also wrapped to be accessible from Python, and use interactive execution to diagnose issues with their scheme.\n",
    "\n",
    "While not strictly necessary, let's run the Fortran cleanup routines to deallocate memory and write any final restart or diagnostic files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv3gfs.wrapper.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a deadlock or hang for another reason (even Python exceptions can cause this sometimes), you will need to look at the ipyparallel log file to see what went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these cells to shut down the cluster if needed, for example to restart in the case of deadlocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are running on the notebook process (instead of the cluster processes) by running %autopx until it says it is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autopx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.shutdown(hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ipcluster stop --profile=mpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to restart the parallel hub, you can shut it down with this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.shutdown(hub=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells list the files in the log directory, and print the first file (in effect a random file). This is useful if you get a crash quickly and only one log file is present. Otherwise, modify the command or write a `%%bash` cell to print the log files you would like to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "log_dir = \"/root/.ipython/profile_mpi/log\"\n",
    "print(os.listdir(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = os.path.join(log_dir, os.listdir(log_dir)[0])\n",
    "print(open(log_filename, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are too many log files for you to find what you're looking for, try deleting the existing logs and re-executing commands to reproduce your issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm /root/.ipython/profile_mpi/log/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
